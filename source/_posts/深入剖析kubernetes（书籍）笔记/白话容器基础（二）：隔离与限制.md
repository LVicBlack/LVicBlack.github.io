---
title: 白话容器基础（二）：隔离与限制
date: 2021-09-25 10:06:00
categories: 
- 深入剖析kubernetes（书籍）笔记
- 容器技术概念入门
tags:
- kubernetes
---

## 隔离与限制

### 容器 VS VM 

虚拟机的缺点：
- 虚拟机需要借助GuestOS才能运行应用，带来了额外的资源消耗和占用；容器实际上就是OS的进程
- 虚拟机自身占用内存较大；容器额外的资源占用几乎可以忽略不计
- 应用对宿主机操作系统的调用要经过虚拟化软件的拦截和处理，尤其对计算资源、网络和磁盘 I/O 的损耗非常大

>“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。

容器的缺点：
- **隔离得不彻底。**

### 隔离

容器的隔离问题
- 既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。
	tips: 这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。
- 在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。
	 tips: 在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。

所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。

### 限制

进程虽然被隔离，通过Namespace的限制。看似它是独立存在的但是因为与其他进程共享资源。所以资源分配可能存在不公平的问题。

>Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。
>Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。

#### Cgroups实践

Ubuntu 16.04 机器

1. 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。

```
$ mount -t cgroup 
cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
...
```

可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。

而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件

```
$ ls /sys/fs/cgroup/cpu
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
```

cfs_period 和 cfs_quota这两个参数可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。

2. 配置文件的使用：
你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：

```
root@ubuntu:/sys/fs/cgroup/cpu$ mkdir container
root@ubuntu:/sys/fs/cgroup/cpu$ ls container/
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
```

这个目录就称为一个“控制组”。操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。

3. 后台执行一条脚本

```
$ while : ; do : ; done &
[1] 226
```

显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。

确认CPU的使用率是否100%（%Cpu0 :100.0 us）

```
$ top
%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
```

4. 查看 container 目录下的cfs_period 和 cfs_quota这两个参数

```
$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 
-1
$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 
100000
```

看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）

5. 修改文件的内容来设置限制

比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）：

```
$ echo 20000 > /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
```

在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。

6. 限制进程

被限制的进程的 PID 写入 container 组里的 tasks 文件：

```
$ echo 226 > /sys/fs/cgroup/cpu/container/tasks 
```

查看CPU

```
$ top
%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
```

可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。

####  Cgroups的子系统资源限制能力

Cgroups 的每一个子系统都有其独有的资源限制能力，比如：

- blkio，为块设备设定I/O 限制，一般用于磁盘等设备；
- cpuset，为进程分配单独的 CPU 核和对应的内存节点；
- memory，为进程设定内存使用的限制。

>Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。

对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。

比如这样一条命令：

```
$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash
```

启动容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认：

```
$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 
100000
$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 
20000
```

这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。

### 容器中 top 等命令看到的CPU和内存等是宿主机的信息

如果在容器里执行 top 指令，就会发现，它显示的信息居然是**宿主机的 CPU 和内存数据，而不是当前容器的数据。**
造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。
**在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。**

#### 解决

把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的/proc/meminfo位置后。容器中进程读取相应文件内容时，LXCFS的FUSE实现会从容器对应的Cgroup中读取正确的内存限制。从而使得应用获得正确的资源约束设定。
kubernetes环境下，也能用，以ds 方式运行 lxcfs ，自动给容器注入争取的 proc 信息。

[lxcfs让pod正确的意识到给自己分配的资源](https://zhuanlan.zhihu.com/p/101059102)

### 总结

>- 容器是『单进程』模型，只有 PID=1 的进程才会被 Dockerd 控制，即 pid=1 的进程挂了 Dockerd 能够感知到，但是其它的进程却不受 Dockerd 的管理，当出现孤儿进程的时候，管理和调度是个问题
>
>- 很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。supervisor可以像systemd一样用启动子进程的方式来启动注册给他的app，他是容器内所有服务的父进程
>
>- 后面分享容器设计模式时，还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够**同生命周期**，这个概念对后续的容器编排非常重要。













